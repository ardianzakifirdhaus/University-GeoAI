{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/University-GeoAI/blob/main/Lab_7a_XML_Land_Cover_Classification_RF_Classifier1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 7a. Explainable Machine Learning in Geospatial Analysis: Land Cover Classification**\n",
        "\n",
        "## Introduction\n",
        "Explainable ML methods are essential for interpreting the decision-making processes of complex or \"black-box\" models. They help identify the most influential input features driving model predictions, thereby enhancing the transparency, interpretability, and trustworthiness of machine learning outcomes."
      ],
      "metadata": {
        "id": "9enVF7go_Y6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup\n",
        "### Import libraries\n",
        "Import the necessary libraries (pandas, numpy, scikit-learn, rasterio, etc.)."
      ],
      "metadata": {
        "id": "-pwDPkalAvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import shap"
      ],
      "metadata": {
        "id": "F6bfz1KZzA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "Next, mount your Google Drive. You will be prompted to authorize access to your Google Drive. Once mounted, you can read/write files in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "bzVfa9mtzRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXvi8JvIzRmY",
        "outputId": "d569e979-1fe0-45e5-82ef-44f8757d55a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths and variables\n",
        "Define the the paths to access your own directory structure in Google Drive. In this tutorial, we use a CSV training dataset (Bul_TrainingData_2024.csv) containing pixel values and their corresponding classes. We will also define the paths to the training datasets and random forest model.\n"
      ],
      "metadata": {
        "id": "l0HWzfHGzVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2024/Bul_TA_S2_Pal_2024.csv'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Bulawayo_Dataset_2024/best_rf_model.pkl'"
      ],
      "metadata": {
        "id": "Vj2kFuhMzVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define target and predictor variables\n",
        "Next, define and specify the overall structure of the land cover classification task. Bands lists the Sentinel-2 spectral bands (e.g., B2, B3, B4) used as input features (predictors) for the model, while LC indicates the target column named “class.”"
      ],
      "metadata": {
        "id": "xaZUI5eOz8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and predictor variables\n",
        "features = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12', 'HV']  # Feature columns\n",
        "label = ['class']\n",
        "\n",
        "Classes = [0, 1, 2, 3, 4, 5]\n",
        "N_Classes = 6\n",
        "Names   = [\"Bare area\", \"Built-up\", \"Cropland\", \"Grassland\", \"Woodland\", \"Water\"]\n",
        "Palette = [\n",
        "    '#D3D3D3',  # grey for class 0 (Bare area)\n",
        "    '#FF0000',  # red for class 1 (Built-up)\n",
        "    '#FFD700',  # gold for class 2 (Cropland)\n",
        "    '#ADFF2F',  # greenyellow for class 3 (Grassland)\n",
        "    '#006400',  # darkgreen for class 4 (Woodland)\n",
        "    '#0000FF'   # blue for class 5 (Water)\n",
        "]"
      ],
      "metadata": {
        "id": "WjFAe4hjM2VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and Prepare Training Data\n",
        "Next, load and prepare the training data. The training data is in a CSV format with columns for each band (B2, B3, etc.) and a class column (land cover type)."
      ],
      "metadata": {
        "id": "ZmtsZJvI3q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[features]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "TcAThBNC3rQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Explainable Machine Learning (xML)\n",
        "### Introduction\n",
        "We will use xML methods such as  SHAP (Shapley Additive exPlanations) model to gain insights in the random forest model.\n",
        "\n",
        "Let's start by loading and extracting the saved random forest model from the dictionary."
      ],
      "metadata": {
        "id": "HKr7p6Snh51x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "package = joblib.load(MODEL_PATH)\n",
        "rf_model = package[\"model\"]\n",
        "features = package[\"features\"]\n",
        "label = package[\"label\"]\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v82c5DFZh-f2",
        "outputId": "1844a6ac-1f55-4bba-ba59-1019a708d31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP (SHapley Additive exPlanations) method\n",
        "Next, we will use the SHAP method. The SHAP (SHapley Additive exPlanations) method is based on the shapley values, which is a concept from cooperative game theory proposed by Lloyd Shapley (1953).\n",
        "\n",
        "Let's create an explainer for the RF model. Explainer prints useful information, especially for resolving potential errors."
      ],
      "metadata": {
        "id": "x_GS7_ypiNx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 1,000 rows from the training data for explainability\n",
        "X_train_sample = X_train.sample(n=1000, random_state=42)\n",
        "\n",
        "# Create SHAP explainer using the smaller sample\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "\n",
        "# Compute SHAP values for the sample only\n",
        "shap_values = explainer(X_train_sample)"
      ],
      "metadata": {
        "id": "4v2HKbvmiTcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP summary plot\n",
        "Finally, display SHAP summary plot to gain insights into the random forest model for only 1000 pixel samples."
      ],
      "metadata": {
        "id": "oabXRnQRCZoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ListedColormap class to create custom colormaps\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Define a custom color palette corresponding to different land cover classes\n",
        "Palette = [\n",
        "    '#FFD700',  # gold - e.g., Cropland\n",
        "    '#ADFF2F',  # greenyellow - e.g., Grassland\n",
        "    '#FF0000',  # red - e.g., Built-up\n",
        "    '#D3D3D3',  # grey - e.g., Bare area\n",
        "    '#006400',  # darkgreen - e.g., Woodland\n",
        "    '#0000FF'   # blue - e.g., Water\n",
        "]\n",
        "\n",
        "# Convert the list of hex colors into a matplotlib colormap\n",
        "my_cmap = ListedColormap(Palette)\n",
        "\n",
        "# Generate a SHAP summary plot to interpret feature importance\n",
        "shap.summary_plot(\n",
        "    shap_values,        # SHAP values for the model predictions\n",
        "    X_train_sample,     # Subsample of training features\n",
        "    feature_names=features,   # Names of the input features\n",
        "    class_names=Names,        # Descriptive labels for each class\n",
        "    color=my_cmap             # Use the custom colormap for class coloring\n",
        ")"
      ],
      "metadata": {
        "id": "BAioYmwACZ-m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}