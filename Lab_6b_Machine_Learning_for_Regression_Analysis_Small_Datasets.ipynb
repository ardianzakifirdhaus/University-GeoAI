{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/University-GeoAI/blob/main/Lab_6b_Machine_Learning_for_Regression_Analysis_Small_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SncSpvGm2VUS"
      },
      "source": [
        "# Lab 6b. Machine Learning for Regression Analysis\n",
        "\n",
        "## Introduction\n",
        "The aim of the script is to model aboveground biomass density (AGBD) using the Global Ecosystem Dynamics Investigation (GEDI) Level 4A (L4A), Sentinel-2 (S2), Normalized Difference Vegetation Index (NDVI), Canopy Chlorophyll Content Index (CCCI), Specific Leaf Area Vegetation Index (SLAVI), and a random forest model.\n",
        "\n",
        "Check tutorial for preparing biomass density training data\n",
        "1. Creating a Training Dataset for Machine Learning | Part 1: GEDI L4A Data Preparation (https://www.youtube.com/watch?v=6y0Ya1dTecI&t=63s)\n",
        "2. Creating a Training Dataset for Machine Learning | Part 2: Combining with Sentinel-2 (https://www.youtube.com/watch?v=WDAhFphWb98)\n",
        "\n",
        "Following are the steps to model AGBD (model 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries\n",
        "\n",
        "Install the necessary libraries."
      ],
      "metadata": {
        "id": "JuDYOSPF1obl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install some packages\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJRpSF_O1yTp",
        "outputId": "431e38c3-0569-4c4d-fc6e-c6a124bae6f4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting earthpy\n",
            "  Downloading earthpy-0.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.0.2)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.4.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from earthpy) (0.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (2.9.0.post0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (0.10.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.1.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (1.15.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->earthpy) (1.17.0)\n",
            "Downloading earthpy-0.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: earthpy\n",
            "Successfully installed earthpy-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, import the following libraries."
      ],
      "metadata": {
        "id": "0tn6cLNE13A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.features import rasterize\n",
        "import earthpy.plot as ep\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "zmIOuwvn17x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMFNO2R3KYa4"
      },
      "source": [
        "# Setting-up Colab\n",
        "## Mount your Google Drive\n",
        "First, make sure that your data is loaded in Google Drive. After that mount your Google Drive using the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ_CuF7GJDyt",
        "outputId": "dfbd29d0-9991-41ff-abd0-d0786117420e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import the neccessary library\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access the raster and vector datasets\n",
        "Import the raster  and vector datasets. Prepare the features and labels."
      ],
      "metadata": {
        "id": "TpWUPUYr2ddS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define predictor and target variables, and the path that contains the datasets\n",
        "FEATURES = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12','NDVI','CCCI','SLAVI']\n",
        "LABEL = ['agbd']\n",
        "SAMPLE_PATH = '/content/drive/My Drive/Maf_Datasets/Small_GEDI_L4A_2022_Dataset1.csv'\n",
        "IMAGE_PATH = '/content/drive/My Drive/Maf_Datasets/S2_predictors_2022.tif'"
      ],
      "metadata": {
        "id": "Ye37SDFR2ckv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create image composites\n",
        "Load and display the imagery."
      ],
      "metadata": {
        "id": "6kP9mRm53irA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "image = rasterio.open(IMAGE_PATH)\n",
        "bandNum = image.count\n",
        "height = image.height\n",
        "width = image.width\n",
        "crs = image.crs\n",
        "transform = image.transform\n",
        "shape = (height, width)\n",
        "\n",
        "image_vis = []\n",
        "for x in [9, 7, 2]:\n",
        "  image_vis.append(image.read(x))\n",
        "image_vis = np.stack(image_vis)\n",
        "\n",
        "plot_size = (8, 8)\n",
        "ep.plot_rgb(\n",
        "  image_vis,\n",
        "  figsize=plot_size,\n",
        "  stretch=True,\n",
        ")"
      ],
      "metadata": {
        "id": "s041LkIe3j3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare datasets for modeling\n",
        "## Import the sample data\n",
        "\n",
        "Next, we are going to load the sample data with the aboveground biomass density (AGBD) and raster variables."
      ],
      "metadata": {
        "id": "S7aH80OU3owy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read sample\n",
        "samples = pd.read_csv(SAMPLE_PATH)[FEATURES + LABEL]\n",
        "samples"
      ],
      "metadata": {
        "id": "C5IhaDAU3u-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training data\n",
        "First, let's split the training points into training and test datasets."
      ],
      "metadata": {
        "id": "_DqtqYqV34FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test\n",
        "train, test = train_test_split(samples, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# Get variables input and output\n",
        "X_train = train[FEATURES]\n",
        "X_test = test[FEATURES]\n",
        "y_train = train[LABEL].astype(float)\n",
        "y_test = test[LABEL].astype(float)\n",
        "\n",
        "# Show the data shape\n",
        "print(f'Train features: {X_train.shape}\\nTest features: {X_test.shape}\\nTrain label: {y_train.shape}\\nTest label: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj2hd_PjtLKC",
        "outputId": "845bb5c3-4c48-47ef-cf21-ff36ca585924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features: (4894, 12)\n",
            "Test features: (1224, 12)\n",
            "Train label: (4894, 1)\n",
            "Test label: (1224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform exploratory data analysis (EDA)\n",
        "Exploratory data analysis (EDA) is an important step in understanding your data before building a machine learning model. To perform EDA on your training dataset, we will use libraries such as pandas for data manipulation and matplotlib or seaborn for data visualization. First, we will start by creating a DataFrame for the training dataset."
      ],
      "metadata": {
        "id": "efn6p8VM7ShN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from X_train and y_train\n",
        "train_df = pd.DataFrame(data=np.c_[X_train, y_train], columns=[f'Band_{i}' for i in range(X_train.shape[1])] + ['agbd'])\n",
        "\n",
        "# Rename columns in the DataFrame train_df\n",
        "train_df.columns = FEATURES + ['agbd']"
      ],
      "metadata": {
        "id": "giJU6rGj4lh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will take a quick look at the top five rows using the DataFrame's head() method."
      ],
      "metadata": {
        "id": "y0km6Hy7kPmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first five rows\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "5H3GaMQikYXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the info() method to get a quick description of the data."
      ],
      "metadata": {
        "id": "FZj9YquolB5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the info()to check the data\n",
        "train_df.info()"
      ],
      "metadata": {
        "id": "971W6zqHlMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use the describe() method to get summary statistics of the training dataset. This will provide statistics such as mean, standard deviation, minimum, maximum, and quartiles for each feature and the target variable."
      ],
      "metadata": {
        "id": "May2v-8k-HEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary statistics\n",
        "summary_stats = train_df.describe()\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "TUbxnEEc-S4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will visualize the distribution and potential outliers of each feature using boxplots. This code will generate a boxplot for each feature, showing the median, quartiles, and any potential outliers."
      ],
      "metadata": {
        "id": "4wSVZ9O0-XQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the seaborn library\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create boxplots for each feature\n",
        "sns.boxplot(data=train_df.drop(columns=['agbd']), orient='v')\n",
        "plt.title('Boxplots of Features')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Spectral reflectance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5aEh9POz-iP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select and Train a Model Training\n",
        "## Training a random forest regression model\n",
        "We will start with a random forest regression model. Note that 'y_train' is now a column-vector."
      ],
      "metadata": {
        "id": "bCVl-YPLnOBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will tune the hyperparameters of the RF model. Parameters like n_estimators, max_depth, and min_samples_split can significantly impact the model's performance. We will use techniques like grid search or random search to find the optimal set of hyperparameters."
      ],
      "metadata": {
        "id": "olC7EktKBqUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the model to the data\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_"
      ],
      "metadata": {
        "id": "Pxl1Ufk5Bq8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use the best parameters obtained from the grid search to train the final RF regression model (RandomForestRegressor)."
      ],
      "metadata": {
        "id": "ai53OakHE56U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best parameters from the grid search\n",
        "best_n_estimators = best_params['n_estimators']\n",
        "best_max_depth = best_params['max_depth']\n",
        "best_min_samples_split = best_params['min_samples_split']\n",
        "\n",
        "# Initialize the RandomForestRegressor with the best parameters\n",
        "best_rf_reg = RandomForestRegressor(\n",
        "    n_estimators=best_n_estimators,\n",
        "    max_depth=best_max_depth,\n",
        "    min_samples_split=best_min_samples_split\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_rf_model = best_rf_reg.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "gJK1-mqlEd_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use K-fold cross validation feature to split the training data into 10 subsets called folds. Then print the RMSE scores."
      ],
      "metadata": {
        "id": "2P_3aI39HHcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the RF model RMSE using cross-validation\n",
        "neg_mse_scores = cross_val_score(best_rf_model, X_train, y_train.values.ravel(),\n",
        "                                 scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# Convert negative MSE to RMSE\n",
        "rmse_scores = np.sqrt(-neg_mse_scores)\n",
        "\n",
        "# Print or use the RMSE scores\n",
        "print(\"RMSE Scores:\", rmse_scores)"
      ],
      "metadata": {
        "id": "s7rGgHA4FMPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a scatter plot for the RF model.\n"
      ],
      "metadata": {
        "id": "Ag_Y-NRk9Trp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test data\n",
        "rf_prediction = best_rf_model.predict(X_test).flatten()\n",
        "label = y_test.values.flatten()\n",
        "\n",
        "# Calculate MBE\n",
        "mbe = np.mean(rf_prediction - label)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(label, rf_prediction))\n",
        "\n",
        "# Calculate R2\n",
        "r2 = r2_score(label, rf_prediction)\n",
        "\n",
        "print(f'Mean Bias Error (MBE): {mbe}')\n",
        "print(f'Root Mean Square Error (RMSE): {rmse}')\n",
        "print(f'R-squared (R2): {r2}')\n",
        "\n",
        "# Calculate the absolute difference between predicted and actual values\n",
        "absolute_diff = np.abs(rf_prediction - label)\n",
        "\n",
        "# Plot the scatter plot with colors based on the absolute difference\n",
        "plt.scatter(label, rf_prediction, c=absolute_diff, cmap='viridis')\n",
        "m, b = np.polyfit(label, rf_prediction, 1)\n",
        "plt.plot(label, m * label + b)\n",
        "plt.title('Reference vs Estimated Mean AGBD (RF Model 1)')\n",
        "plt.xlabel('GEDI reference Mean AGBD (Mg/ha)')\n",
        "plt.ylabel('Estimated Mean AGBD (Mg/ha)')\n",
        "plt.colorbar(label='Absolute Difference')  # Adding a colorbar for reference\n",
        "plt.legend(['Regression Line: y = {:.2f}x + {:.2f}'.format(m, b)])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jm3HGF5g9YRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the best RF model\n",
        "Let's save the best RF model parameters, feature names, or other metadata together."
      ],
      "metadata": {
        "id": "gCW3qG0GUanj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# joblib library or module.\n",
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "MODEL_PATH = '/content/drive/MyDrive/Maf_Datasets/best_rf_model.pkl'\n",
        "\n",
        "model_package = {\n",
        "    \"model\": best_rf_model,\n",
        "    \"features\": FEATURES,\n",
        "    \"label\": LABEL\n",
        "}\n",
        "joblib.dump(model_package, MODEL_PATH)\n",
        "\n",
        "# Load with:\n",
        "package = joblib.load(MODEL_PATH)\n",
        "loaded_model = package[\"model\"]"
      ],
      "metadata": {
        "id": "qgx2OVmHUbQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and display agbd map\n",
        "Next, we will predict and display agbd map. Note that the final agbd image map will be exported as a GeoTIFF file, which can be visualized in any GIS software."
      ],
      "metadata": {
        "id": "RvBGwbQypqLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all 12 bands from the image (assuming 12-band image)\n",
        "image_input = []\n",
        "for x in range(12):\n",
        "    image_input.append(image.read(x + 1))\n",
        "image_input = np.stack(image_input).reshape(12, -1).T  # shape: (pixels, features)\n",
        "\n",
        "# Predict using the trained Random Forest model\n",
        "rf_prediction = best_rf_model.predict(image_input)\n",
        "\n",
        "# Reshape prediction to 2D image\n",
        "rf_prediction = rf_prediction.reshape(shape[0], shape[1])\n",
        "\n",
        "# Visualize the predicted raster\n",
        "ep.plot_bands(rf_prediction, cmap='YlGn', figsize=plot_size)"
      ],
      "metadata": {
        "id": "W8kQSpPh6ihV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export to Drive\n",
        "Save the predicted AGBD map from the RF model as geotiff."
      ],
      "metadata": {
        "id": "mLUTwd488I-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save file to drive\n",
        "save_location = '/content/drive/My Drive/Maf_Datasets/'\n",
        "name = 'RF_Small_AGBD_2022a.tif'\n",
        "location = save_location + name\n",
        "\n",
        "new_dataset = rasterio.open(\n",
        "      location,\n",
        "      mode='w', driver='GTiff',\n",
        "      height = rf_prediction.shape[0], width = rf_prediction.shape[1],\n",
        "      count=1, dtype=str(rf_prediction.dtype),\n",
        "      crs=crs,\n",
        "      transform=transform\n",
        ")\n",
        "new_dataset.write(rf_prediction, 1);\n",
        "new_dataset.close()"
      ],
      "metadata": {
        "id": "AttCWBRn8H7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTNckM1HugqoBhC+crmH4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}